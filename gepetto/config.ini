[Gepetto]
MODEL = gpt-4o-mini

# Specify the program language. It can be "fr_FR", "zh_CN", or any folder in locales. Defaults to English.
LANGUAGE = 

# the name of the python module
API_PROVIDER = sider

[OpenAI]
# Set your API key here, or put it in the OPENAI_API_KEY environment variable.
API_KEY = 

# Set your OpenAI proxy here. Example: OPENAI_PROXY = 127.0.0.1:7890
OPENAI_PROXY =

# Base URL if you want to redirect requests to a different / local model.
# Can also be provided via the OPENAI_BASE_URL environment variable.
# Leave blank unless you know what you are doing :)
BASE_URL =

[Groq]
# OPTIONAL, create a Groq account only if you want to use the LLaMA models.
# Set your API key here, or put it in the GROQ_API_KEY environment variable.
API_KEY =

# Set your Groq proxy here. It will be used for all protocols.
GROQ_PROXY =

# Base URL if you want to redirect requests to a different / local model.
# Can also be provided via the GROQ_BASE_URL environment variable.
BASE_URL =

[Together]
# Optional, create a Together account only if you want to use the Mistral models.
# Set your API key here, or put it in the TOGETHER_API_KEY environment variable.
API_KEY =

# Base URL if you want to redirect requests to a different / local model.
# Can also be provided via the TOGETHER_BASE_URL environment variable.
BASE_URL =

[Ollama]
# Endpoint used to connect to the Ollama API. Default is http://localhost:11434
HOST =

[Sider]
# Added in the fork https://github.com/qfcy/Gepetto

TOKEN = 
CONTEXT_ID =
COOKIE =